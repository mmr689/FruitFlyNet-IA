{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b4796f3",
   "metadata": {},
   "source": [
    "# 2. Train data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ca99d",
   "metadata": {},
   "source": [
    "## Resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dff977",
   "metadata": {},
   "source": [
    "Este cuaderno representa la segunda etapa del proyecto. Cómo el objetivo es desarrollar diferentes modelos que sean capaces de clasificar si una imagen contiene o no la mosca de la fruta, **realizaremos previamente un aumento de los datos de entrenamiento** de tal manera que todos los modelos hagan uso del mismo *dataset*.\n",
    "\n",
    "Por lo tanto en este cuaderno el objetivo es,\n",
    "1. Dividir el conjunto de datos en *train/test*.\n",
    "2. Realizar y guardar el aumento de las imágenes de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00d05d1",
   "metadata": {},
   "source": [
    "## Código"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af86cb",
   "metadata": {},
   "source": [
    "### Dependencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bb2041",
   "metadata": {},
   "source": [
    "Las versiones empleadas en el cuaderno han sido:\n",
    "* Python version: 3.11.3\n",
    "* NumPy version: 1.23.5\n",
    "* OpenCV version: 4.7.0\n",
    "* Albumentations version: 1.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd89917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.3\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d91acfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.23.5\n",
      "OpenCV version: 4.7.0\n",
      "Albumentations version: 1.3.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "import albumentations\n",
    "\n",
    "print(\"NumPy version:\", numpy.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)\n",
    "print(\"Albumentations version:\", albumentations.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a44f60d",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa0c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec9f7673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f5212a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3602310",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819bb9ad",
   "metadata": {},
   "source": [
    "* **data_restruct:** \n",
    "* **data_augment:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bac01d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_restruct(path, seed):\n",
    "    # Lista de etiquetas\n",
    "    labels = os.listdir(path)\n",
    "    # Cargar las imágenes y las etiquetas\n",
    "    X, y, names = [], [], []\n",
    "    for i, label in enumerate(labels):\n",
    "        img_names = os.listdir(os.path.join(path, label))\n",
    "        for img_name in img_names:\n",
    "            img_path = os.path.join(path, label, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img.shape[0] != 32 or img.shape[1] != 32:\n",
    "                print(img_name, label)\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            X.append(img)\n",
    "            y.append(i)\n",
    "            names.append(img_name)\n",
    "            \n",
    "    # Mezclar las listas\n",
    "    combinadas = list(zip(X, y, names))\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    random.shuffle(combinadas)\n",
    "    # Desempaquetar las listas mezcladas en dos listas separadas\n",
    "    X, y, names = zip(*combinadas)\n",
    "            \n",
    "    return np.array(X), np.array(y), np.array(names), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7220709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(img, transform, n=5, n_fixed = True):\n",
    "    \"\"\"\n",
    "    Función para llevar a cabo aumento de las imágenes.\n",
    "    Inputs:\n",
    "        · img (np.array): Imagen a transformar.\n",
    "        · transform (Albumentations object): Pipeline con las posibles acciones a llevar en la imagen.\n",
    "        · n (int)\n",
    "        · n_fixed (bool): Define si n es la cantidad de transformaciones a realizar o la cantidad de veces que se intenta.\n",
    "    Outputs:\n",
    "        · - (np.array): Array con las transformaciones realizadas.\n",
    "    \"\"\"\n",
    "    res, counter = [], 0\n",
    "    while True:\n",
    "        transf = transform(image=img)['image']\n",
    "        # Si la transf. resultante es diferente del original y diferente a las nuevas alteraciones\n",
    "        if not np.array_equal(img, transf) and not np.isin(transf, res).all():\n",
    "            res.append(transf)\n",
    "        if (n_fixed == True and len(res) >= n) or (n_fixed == False and counter >= n) or (n_fixed == False and len(res) >= n):\n",
    "            return np.stack(res, axis=0)\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "def data_augment_validation(augmentations):\n",
    "    \"\"\"\n",
    "    Función para validar que el proceso de aumento de datos ha ido bien.\n",
    "    1. comprobar si ha habido al menos una alteración de la imagen. Este factor realmente no es restrictivo,\n",
    "    simplemente queremos controlarlo.\n",
    "    2. Comprobar que no se ha colado ninguna imagen repetida\n",
    "    \"\"\"\n",
    "    # Comprobamos si NO se ha realizado ninguna transformación\n",
    "    if augmentations.shape[0] == 0:\n",
    "        print(name)\n",
    "        print('ups')\n",
    "    # Validamos que no hay arrays (imgs) repetidos en la lista\n",
    "    unique, counts = np.unique(np.array(list(augmentations)), axis=0, return_counts=True)\n",
    "    if len(unique[counts > 1]) > 0:\n",
    "        print(name)\n",
    "        print('Arrays repetidos:', repeated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe32b86",
   "metadata": {},
   "source": [
    "### Main pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c7753",
   "metadata": {},
   "source": [
    "El primer paso será importar el conjunto de datos que los propios **zoólogos del grupo ZAP de la UIB** han etiquetado ayudándonos de la función `data_restruct()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fa345d43",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ·X: (84, 32, 32, 3)\n",
      " ·y: (84,)\n",
      " ·names: (84,)\n",
      " ·labels: 4\n"
     ]
    }
   ],
   "source": [
    "folder_path = r'C:\\Users\\migue\\OneDrive - Universitat de les Illes Balears\\Proyectos\\ZAP\\FruitFlyNet\\scripts\\dataset\\original'\n",
    "X, y, names, labels = data_restruct(folder_path, seed=1)\n",
    "\n",
    "print(' ·X:',X.shape)\n",
    "print(' ·y:',y.shape)\n",
    "print(' ·names:',names.shape)\n",
    "print(' ·labels:',len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "90582ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fly', 'frame', 'small black bug', 'trap']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2b4ed84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'230518185338.png'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a989a2",
   "metadata": {},
   "source": [
    "Observamos cuantos datos tenemos para cada etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "51188e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fly: 21\n",
      "frame: 21\n",
      "small black bug: 21\n",
      "trap: 21\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for la, co in zip(labels, counts):\n",
    "    print(f'{la}: {co}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd45e826",
   "metadata": {},
   "source": [
    "Ya tenemos los datos de trabajo, **dividimos los datos en *train/test***.\n",
    "* 80% para *train*.\n",
    "* 20% para *test*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4b372d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PER = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ed307e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 32, 32, 3)\n",
      "(67,)\n",
      "(17, 32, 32, 3)\n",
      "(17,)\n"
     ]
    }
   ],
   "source": [
    "train_len = int(X.shape[0] * TRAIN_PER)\n",
    "X_train, X_test = np.split(X, [train_len])\n",
    "y_train, y_test = np.split(y, [train_len])\n",
    "names_train, names_test = np.split(names, [train_len])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed2707b",
   "metadata": {},
   "source": [
    "Una vez tenemos los datos de trabajo, **realizamos el proceso de aumento del *dataset***. Para ello primero definimos \n",
    "* cuantas imágenes nuevas queremos generar,\n",
    "* si este valor es fijo o no\n",
    "* y las transformadas a realizar junto a la probabilidad de que estas sucedan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3fd4373",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, N_FIXED = 10, False\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde667c9",
   "metadata": {},
   "source": [
    "Realizamos el proceso para cada una de las imágenes. Las nuevas imágenes tendrán la etiqueta `augmented` en su nombre para poder diferenciarlas de la original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a21052f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(445, 32, 32, 3)\n",
      "(445,)\n",
      "(445,)\n"
     ]
    }
   ],
   "source": [
    "for img_index in range(X_train.shape[0]):\n",
    "    # Obtenemos la imagen y etiqueta a trabajar y aplicamos data augmentation\n",
    "    img, target, name = X_train[img_index], y_train[img_index], names_train[img_index]\n",
    "    augmentations = data_augment(img, transform, n=N, n_fixed=N_FIXED)\n",
    "    # Validación del aumento de datos\n",
    "    data_augment_validation(augmentations)\n",
    "    # Añadimos a nuestro dataset las imágenes aumentadas, etiquetas y nombres\n",
    "    X_train = np.concatenate((X_train, augmentations), axis=0)\n",
    "    y_train = np.append(y_train, np.full(augmentations.shape[0], target))\n",
    "    name = name.split('.')\n",
    "    name, ext = name[0], name[1]\n",
    "    full_names = [name+'_augmented_'+str(i+1)+'.'+ext for i in range(augmentations.shape[0])]\n",
    "    names_train = np.append(names_train, full_names)\n",
    "        \n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(names_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d0d81",
   "metadata": {},
   "source": [
    "Finalmente guardamos nuestro nuevo *dataset* que contiene las imágenes así cómo las diferentes versiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "16e3d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mezclamos el conjunto de datos\n",
    "combinadas = list(zip(X_train, y_train, names_train))\n",
    "random.shuffle(combinadas)\n",
    "X_train, y_train, names_train = zip(*combinadas)\n",
    "\n",
    "# Comprobamos (y/o creamos) si la carpeta destino existe\n",
    "path = 'C:/Users\\migue/OneDrive - Universitat de les Illes Balears/Proyectos/ZAP/FruitFlyNet/scripts/dataset/'\n",
    "folder = 'augmented_dataset'\n",
    "full_path = os.path.join(path, folder)\n",
    "try: os.mkdir(full_path)\n",
    "except FileExistsError: pass\n",
    "\n",
    "# Creamos la carpeta de train\n",
    "full_train_path = os.path.join(full_path, 'train')\n",
    "try: os.mkdir(full_train_path)\n",
    "except FileExistsError: pass\n",
    "for i,val in enumerate(zip(X_train, y_train, names_train)):\n",
    "    # Desempaquetamos y generamos la ruta\n",
    "    img, target, name = val\n",
    "    label_path = os.path.join(full_train_path, labels[target])\n",
    "    # Validamos si ya existe la carpeta\n",
    "    try: os.mkdir(label_path)\n",
    "    except FileExistsError: pass\n",
    "    # Guardamos la imagen\n",
    "    final_path = os.path.join(label_path, name)\n",
    "    cv2.imwrite(final_path, cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    \n",
    "# Creamos la carpeta de test\n",
    "full_test_path = os.path.join(full_path, 'test')\n",
    "try: os.mkdir(full_test_path)\n",
    "except FileExistsError: pass\n",
    "for i,val in enumerate(zip(X_test, y_test, names_test)):\n",
    "    # Desempaquetamos y generamos la ruta\n",
    "    img, target, name = val\n",
    "    label_path = os.path.join(full_test_path, labels[target])\n",
    "    # Validamos si ya existe la carpeta\n",
    "    try: os.mkdir(label_path)\n",
    "    except FileExistsError: pass\n",
    "    # Guardamos la imagen\n",
    "    final_path = os.path.join(label_path, name)\n",
    "    cv2.imwrite(final_path, cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
